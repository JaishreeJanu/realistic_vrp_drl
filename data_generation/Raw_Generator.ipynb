{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('berlin_coordinates.npy', 'rb') as f:\n",
    "    coordinate = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: routingpy in /Users/sophialawal/opt/anaconda3/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/sophialawal/opt/anaconda3/lib/python3.9/site-packages (from routingpy) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/sophialawal/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->routingpy) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sophialawal/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->routingpy) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sophialawal/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->routingpy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sophialawal/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20.0->routingpy) (2022.9.24)\n"
     ]
    }
   ],
   "source": [
    "!pip install routingpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup OSRM \n",
    "from routingpy import OSRM\n",
    "from routingpy.routers import options\n",
    "options.default_timeout=None\n",
    "from sklearn.preprocessing import normalize\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import random\n",
    "\n",
    "client = OSRM(base_url=\"https://router.project-osrm.org\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "def generate(coordinate, graphsize=10, num_sample=100000, batch=1000):\n",
    "    n = graphsize + 1\n",
    "    rng = np.random.default_rng(1235)\n",
    "\n",
    "    \n",
    "    #demand = rng.randint(1,10,[num_sample,n,1])\n",
    "    # Set the demand of depot to true\n",
    "    #demand[:,0]=0\n",
    "    #data = np.concatenate([instances,demand],2)\n",
    "\n",
    "    client = OSRM(base_url=\"https://router.project-osrm.org\")\n",
    "    # instead of looping through the instances/coordinates\n",
    "    # try to generate 10k or 15k examples at once\n",
    "    # Such that if we are required to generate 500k instance we will do that 100 times\n",
    "    # We can generate let say 50k but I want we use all the 835 coordinate\n",
    "    # After every batch, we will sample a new 100 random coordinates\n",
    "    graphs = []\n",
    "    demands = []\n",
    "    distances= []\n",
    "    times = []\n",
    "    for i in range(0, num_sample, batch):\n",
    "\n",
    "        # Sample 100 random coordinates\n",
    "        coord_len = len(coordinate)\n",
    "        coord_idx = np.random.choice(coord_len, size=(100), replace=True)\n",
    "        coord_100 = coordinate[coord_idx]\n",
    "        #coord = np.flip(coord_100) \n",
    "        idx = list(range(len(coord_100)))\n",
    "        \n",
    "        dist_matrix = client.matrix(coord_100, profile=\"car\", sources= idx[0] ,destinations= idx)\n",
    "        if np.any(dist_matrix.distances):\n",
    "            pass\n",
    "        else:\n",
    "            dist_matrix = client.matrix(coord_100, profile=\"car\", sources= idx[0] ,destinations= idx)\n",
    "            \n",
    "        graph_size_idx = rng.choice(idx, size=(batch,n), replace=True)\n",
    "\n",
    "        # Get graph coordinates\n",
    "        graph = coord_100[graph_size_idx]\n",
    "        graphs.append(graph)\n",
    "\n",
    "        print(np.array(dist_matrix.distances).shape)\n",
    "\n",
    "        # Get distance and time matrix\n",
    "        col = np.full((batch,n,n), graph_size_idx.reshape(batch,-1,n))\n",
    "        #print(type(dist_matrix.distances))\n",
    "        row = np.transpose(col, (0,2,1))\n",
    "        distances.append(np.array(dist_matrix.distances)[row,col])\n",
    "        times.append(np.array(dist_matrix.durations)[row,col])\n",
    "\n",
    "        # Get demand\n",
    "        demand = np.random.randint(low=10, high=50, size=(batch,n))\n",
    "        # set depot to zero\n",
    "        demand[:,0] = 0\n",
    "        demands.append(demand)\n",
    "\n",
    "        # dist_matrix returns 100 x 100 \n",
    "        #distance.append(dist_matrix.distances)\n",
    "        #duration.append(dist_matrix.durations)\n",
    "        \n",
    "        # Now we will generate the first 10k batch\n",
    "        #Since we have 100 cordinates, Sample 10k by n idx\n",
    "        # To be able to index distance matrix, we need indices for row and col\n",
    "        # These indices will be of the shape 10k x n x n\n",
    "        # Such that the returned distance matrix is  10k x n x n \n",
    "        # Futher more we will get the cordinate 10k x n\n",
    "        # The demand 10k x n, the depot has a demand of zero\n",
    "     \n",
    "    with open(f'dataset_{num_sample}_{graphsize}.npy', 'wb') as f:\n",
    "        np.save(f, np.concatenate(graphs))\n",
    "        np.save(f, np.concatenate(demands))\n",
    "        np.save(f, np.concatenate(distances))\n",
    "        np.save(f, np.concatenate(times))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    return (graphs, demands, distances)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(coordinate, graphsize=10, num_sample=100000, batch=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRPDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        self._graphs,self._demands, self._distances, self._time = VRPDataset.open_file(path)\n",
    "        _,self.nrow, _ = self._graphs.shape\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._graphs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        nrow, _ = self._graphs[idx].shape\n",
    "        padding = np.ones((nrow, 2))\n",
    "        # Indicates if a node is a depot or not\n",
    "        \n",
    "        padding[1:,0] = 0\n",
    "        padding[0,1] = 0\n",
    "        # Preprocessing\n",
    "        demand = self._demands[idx]\n",
    "        demand = normalize(demand.reshape(1,-1))\n",
    "        graph = normalize(self._graphs[idx])\n",
    "        node_features = np.concatenate([padding,demand.T,graph], axis=1)\n",
    "        edge_features = np.divide(self._distances[idx],1000)\n",
    "        #data = self.vrpdataset[index]\n",
    "        #node_features = data[:20] # To be changed\n",
    "        #edge_features = data[20:] # To Do\n",
    "        return {\n",
    "            'node_features':torch.from_numpy(node_features),\n",
    "            'edge_features':torch.from_numpy(edge_features),\n",
    "            'coordinates':torch.from_numpy(self._graphs[idx])\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "        \n",
    "    @staticmethod\n",
    "    def open_file(path):\n",
    "        with open(path, 'rb') as f:\n",
    "            graphs = np.load(f)\n",
    "            demands = np.load(f)\n",
    "            distances = np.load(f)\n",
    "            times = np.load(f)\n",
    "        return graphs, demands, distances,times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset_200_10.npy'\n",
    "data = VRPDataset(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(data, batch_size=64, shuffle=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1387d92700c54d4d514431281ecc2b3231d92b1ea15940f3ea3e2964d72c4e65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
